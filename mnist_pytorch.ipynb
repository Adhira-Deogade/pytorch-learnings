{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ7-BGFojlX2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOR5XvuPjq-g",
        "outputId": "a3c52909-f028-4864-f39f-ce8f24e25b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 13832327.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 303832.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5496114.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 3727304.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets\n",
        "mnist_training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "mnist_test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTdnE6ork7qH",
        "outputId": "6f174b01-b1e5-406d-9065-fc201dd5d7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 49507565.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1765594.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 12227574.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2462581.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "mnist_train_dataloader = DataLoader(mnist_training_data, batch_size=batch_size)\n",
        "mnist_test_dataloader = DataLoader(mnist_test_data, batch_size=batch_size)\n",
        "\n",
        "for  X, y in mnist_test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape}, {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC69vlczlPHO",
        "outputId": "df8596bd-1fc2-49e5-94e0-4ba09cd70b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]), torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for  X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape}, {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4f7VlAqjuic",
        "outputId": "363d9e07-7062-40e0-c425-5ba8b1a7110c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]), torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Models\n",
        "\n",
        "# To define a neural network in PyTorch,\n",
        "# we create a class that inherits from nn.Module.\n",
        "# We define the layers of the network in the __init__ function\n",
        "# and specify how data will pass through the network in the forward function.\n",
        "# To accelerate operations in the neural network,\n",
        "# we move it to the GPU or MPS if available."
      ],
      "metadata": {
        "id": "EfMFrFaSjxUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using device {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGX6gyDZkN__",
        "outputId": "1d61a763-b672-4ce5-f865-179e1eb3d75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.softmax_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        # nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.softmax_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZcytuJekf-B",
        "outputId": "f22ba065-efc5-48ca-9e1d-83662c07200f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (softmax_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing the model parameters\n",
        "# To train a model we need\n",
        "# 1. a loss function\n",
        "# 2. an optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(f\"Loss function = {loss_fn}\")\n",
        "print(f\"Optimizer = {optimizer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7VOd8balvt5",
        "outputId": "2f198ccd-518f-48b9-d306-1c50513f1562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function = CrossEntropyLoss()\n",
            "Optimizer = Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a single training loop,\n",
        "# the model makes predictions on the training dataset (fed to it in batches)\n",
        "# and brackpropagates the prediction error to adjust the model's parameters"
      ],
      "metadata": {
        "id": "guulcYQUmfwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  print(f\"Dataloader type = {type(dataloader)}\")\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch%100 == 0:\n",
        "      loss, current = loss.item(), (batch+1)*len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/ {size:>5d}]\")"
      ],
      "metadata": {
        "id": "r2926oOzoZCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We also check the model's performance against the tes dataset to ensure it is learning\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "cjq5YIPQqbaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The training process is conducted over several epochs/ iterations.\n",
        "# During each epoch, the model learns parameters to make better predictions.\n",
        "# We print the model's accuracy and loss at each epoch; we'd like to see\n",
        "# the accuracty increase and loss decreasing with every epoch\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------\")\n",
        "  train(mnist_train_dataloader, model, loss_fn, optimizer)\n",
        "  test(mnist_test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEqbIkfjrQGP",
        "outputId": "58cddf87-9189-441f-abdc-a46674b90251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------\n",
            "Dataloader type = <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "loss: 2.312617 [   64/ 60000]\n",
            "loss: 0.281910 [ 6464/ 60000]\n",
            "loss: 0.202289 [12864/ 60000]\n",
            "loss: 0.241962 [19264/ 60000]\n",
            "loss: 0.133777 [25664/ 60000]\n",
            "loss: 0.347707 [32064/ 60000]\n",
            "loss: 0.124561 [38464/ 60000]\n",
            "loss: 0.274744 [44864/ 60000]\n",
            "loss: 0.337179 [51264/ 60000]\n",
            "loss: 0.138242 [57664/ 60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.138237\n",
            "\n",
            "Epoch 2\n",
            "-------------------\n",
            "Dataloader type = <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "loss: 0.087840 [   64/ 60000]\n",
            "loss: 0.115749 [ 6464/ 60000]\n",
            "loss: 0.092728 [12864/ 60000]\n",
            "loss: 0.110904 [19264/ 60000]\n",
            "loss: 0.048080 [25664/ 60000]\n",
            "loss: 0.137385 [32064/ 60000]\n",
            "loss: 0.039759 [38464/ 60000]\n",
            "loss: 0.153590 [44864/ 60000]\n",
            "loss: 0.131135 [51264/ 60000]\n",
            "loss: 0.083268 [57664/ 60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.136621\n",
            "\n",
            "Epoch 3\n",
            "-------------------\n",
            "Dataloader type = <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "loss: 0.084938 [   64/ 60000]\n",
            "loss: 0.097475 [ 6464/ 60000]\n",
            "loss: 0.066811 [12864/ 60000]\n",
            "loss: 0.110022 [19264/ 60000]\n",
            "loss: 0.028248 [25664/ 60000]\n",
            "loss: 0.076764 [32064/ 60000]\n",
            "loss: 0.014675 [38464/ 60000]\n",
            "loss: 0.062219 [44864/ 60000]\n",
            "loss: 0.132465 [51264/ 60000]\n",
            "loss: 0.044377 [57664/ 60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.096473\n",
            "\n",
            "Epoch 4\n",
            "-------------------\n",
            "Dataloader type = <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "loss: 0.043399 [   64/ 60000]\n",
            "loss: 0.083085 [ 6464/ 60000]\n",
            "loss: 0.038029 [12864/ 60000]\n",
            "loss: 0.184250 [19264/ 60000]\n",
            "loss: 0.025430 [25664/ 60000]\n",
            "loss: 0.094798 [32064/ 60000]\n",
            "loss: 0.023711 [38464/ 60000]\n",
            "loss: 0.064011 [44864/ 60000]\n",
            "loss: 0.131460 [51264/ 60000]\n",
            "loss: 0.009788 [57664/ 60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.244418\n",
            "\n",
            "Epoch 5\n",
            "-------------------\n",
            "Dataloader type = <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "loss: 0.067227 [   64/ 60000]\n",
            "loss: 0.032690 [ 6464/ 60000]\n",
            "loss: 0.026843 [12864/ 60000]\n",
            "loss: 0.112316 [19264/ 60000]\n",
            "loss: 0.025341 [25664/ 60000]\n",
            "loss: 0.017142 [32064/ 60000]\n",
            "loss: 0.004448 [38464/ 60000]\n",
            "loss: 0.013417 [44864/ 60000]\n",
            "loss: 0.110253 [51264/ 60000]\n",
            "loss: 0.058284 [57664/ 60000]\n",
            "Test Error: \n",
            " Accuracy: 97.4%, Avg loss: 0.100046\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "#  serialize the internal state dictionary - containing the model parameters\n",
        "\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model Steat to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIE12kVjskOw",
        "outputId": "17de18bf-e3e7-44ce-e9dd-425d93117930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model Steat to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading models\n",
        "# Re-create model structure and loading the state dictionary into it\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ibs-Ox8totE",
        "outputId": "cc913e37-80a2-443e-dce7-8b537d8edc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make new predictions\n",
        "\n",
        "# classes = [\n",
        "\n",
        "# ]\n",
        "x, y = mnist_test_data[0][0], mnist_test_data[0][1]\n",
        "print(f\"X, y = {X[0][0][0]}, {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5SoK5rNt43s",
        "outputId": "3f3d2e8c-883c-43d3-d8b0-e52498352b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X, y = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.]), 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = test_data[0][0], test_data[0][1]\n",
        "print(f\"X, y = {X[0][0][0]}, {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jljxdip4uMYU",
        "outputId": "0e8b6fa2-6397-40f5-9451-14d76a55a827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X, y = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.]), 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[2][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1nib26Pvc8F",
        "outputId": "4f062b83-d3c3-4b2b-d0ec-4d4430f9fd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Pullover\", Actual: \"Trouser\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = list(range(0,10))\n",
        "# print(f\"Classes = {classes}\")\n",
        "right_ones, wrong_ones = 0, 0\n",
        "softmax_fn = torch.nn.Softmax()\n",
        "model.eval()\n",
        "for i in range(10,20):\n",
        "  x, y = mnist_test_data[i][0], mnist_test_data[i][1]\n",
        "  with torch.no_grad():\n",
        "      x = x.to(device)\n",
        "      pred = model(x)\n",
        "      pred = softmax_fn(pred)\n",
        "      # print(f\"Pred = {pred}\")\n",
        "      predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "      # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "      if predicted==actual:\n",
        "        right_ones += 1\n",
        "print(f\"Right % = {(right_ones/10)*100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjTtfqLRvxib",
        "outputId": "0571efd7-e109-444f-9c17-358234651682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right % = 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of training data = {len(training_data)}\")\n",
        "print(f\"Length of test data = {len(test_data)}\")\n",
        "\n",
        "print(f\"Length of mnist training data = {len(mnist_training_data)}\")\n",
        "print(f\"Length of mnist test data = {len(mnist_test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iuA8ZQ-wZOq",
        "outputId": "16750ead-0607-45f2-d68f-8d681bf0191e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data = 60000\n",
            "Length of test data = 10000\n",
            "Length of mnist training data = 60000\n",
            "Length of mnist test data = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qALbrQYMxmAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}